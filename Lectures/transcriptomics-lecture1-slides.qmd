---
title: "Transcriptomics: Lecture 1"
subtitle: |
  | Biotech 7005/Bioinf 3000
  | Frontiers of Biotechnology: Bioinformatics and Systems Modelling
  | The University of Adelaide
author: "Dr Stevie Pederson (They/Them)<br>stevie.pederson@thekids.org.au"
email: "stevie.pederson@thekids.org.au"
institute: |
  | Black Ochre Data Labs
  | The Kids Research Institute Australia
date: "2025-09-01"
date-format: "long"
bibliography: transcriptomics/references.bib
format: 
  revealjs:
    theme: [transcriptomics/custom.scss]
    height: 720
    width: 1280
    sansfont: Times New Roman
    slide-number: c
    show-slide-number: all
    include-after-body: transcriptomics/uoa_bodl_logos.html
  html: 
    css: [transcriptomics/custom.scss]
    output-file: transcriptomics1-lecture1.html
    embed-resources: true    
    toc: true
    toc-depth: 2
    include-in-header: transcriptomics/uoa_bodl_logos.html
---


## [Welcome To Country]{.text-red}

::: {.text-red}

*I'd like to acknowledge the Kaurna people as the traditional owners and custodians of the land we know today as the Adelaide Plains, where I live & work.*
<br><br>
*I also acknowledge the deep feelings of attachment and relationship of the Kaurna people to their place.*
<br><br>
*I pay my respects to the cultural authority of Aboriginal and Torres Strait Islander peoples from other areas of Australia, and pay our respects to Elders past, present and emerging, and acknowledge any Aboriginal Australians who may be with us today*

:::

# Introduction To Transcriptomics

## Introduction

- Postdoctoral Bioinformatician, Black Ochre Data Labs, Adelaide
- Working in collaboration with members of the SA Aboriginal community
- Multi-omics project to identify and address the underlying causes of high T2D rates and complications
    + Using genomics, epigenomics, transcriptomics and other layers
    + My focus is on the transcriptomics layer


## Why Transcriptomics?

:::: {.columns}

::: {.column}

- DNA can be described as being like a giant book of instructions
- Some regions are defined as *genes*
    + Originally considered to be the basic unit of inheritance
    + Now commonly used to describe a region of DNA transcribed into RNA

:::
::: {.column}

::: {.fragment}

::: {style="font-size: 60%; text-align: center;"}

![](transcriptomics/DNA_to_protein_or_ncRNA.png)
<br>By <a href="//commons.wikimedia.org/wiki/User:Evolution_and_evolvability" title="User:Evolution and evolvability">Thomas Shafee</a> - <span class="int-own-work" lang="en">Own work</span>, <a href="https://creativecommons.org/licenses/by/4.0" title="Creative Commons Attribution 4.0">CC BY 4.0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=39441809">Wikimedia Link</a>

:::
:::
:::

::::

## Why Transcriptomics? {.slide-only .unlisted}

- DNA $\rightarrow$ mRNA $\rightarrow$ Proteins
    + Commonly referred to as the Central Dogma of Biology
- Proteins are the *workhorses* of the cell & body
    + Do most of the work, and are responsible for most of the structure
    + Examples like keratin (hair), haemoglobin (oxygen transport) etc
  
::: {.fragment}
  
- ncRNAs are also highly functional
    + Ribosomal RNA (rRNA) essential for translation from mRNA to Protein
    + microRNAs play a role in gene-regulation via mRNA stability
    + The lncRNA Xist coats the *entire X chromosome* during X inactivation
    
:::

## Why Transcriptomics? {.slide-only .unlisted}

### Definition

Based on @Wang2009-hf

> The transcriptome can be defined as the complete set of (RNA) transcripts in a cell, or a population of cells, for a specific developmental stage or physiological condition 


::: {.fragment}
- Transcriptomics is simply the study of the transcriptome
- Can be the *entire RNA content of a cell* (or cells) or a subset of molecules (e.g. mRNA, miRNA)
:::

## Why Transcriptomics? {.slide-only .unlisted}

:::: {.columns}

::: {.column}
![Taken from @Fang2015-uq](transcriptomics/pgen.1005668.g006.png)
:::

::: {.column}
- Most RNA is single-stranded but can have extremely complex structure
    + Shown is a 2kb region from the lncRNA Xist (17kb in total)
- Also interacts with the antisense lncRNA Tsix

:::

::::

## Why Transcriptomics? {.slide-only .unlisted}

- Is a snapshot of the **dynamic biological processes** associated with a biological question
- Use to make inference about these processes
    + Identify therapeutic targets for Cardiovascular Disease
    + Biomarkers for CAR-T cells
    + Key drivers of correlated gene networks
    + Early drivers of neurodegeneration in Alzheimer's
- Assumed to be low-level
    + DNA $\rightarrow$ [RNA]{.text-red} [$\rightarrow$ Protein $\rightarrow$ Metabolites, Signalling molecules, etc ...]{.fragment}

## Why Transcriptomics? {.slide-only .unlisted}

- Is the first molecular level where quantity becomes a key aspect
    + Highly-expressed, or low-expressed genes are important
    + Changes in response to stimulus impact gene expression levels

::: {.fragment}
- Much of the early transcriptomic analyses were quantitative
    + Sequence variation often captured at DNA-level
- Now extending to transcript structure and modifications
    + Identification of fusion transcripts, RNA-methylation etc

:::

## Why Transcriptomics? {.slide-only .unlisted}

- Early techniques were often using large numbers of cells
    + Often multiple cell types within a biological sample
- Modern techniques are incredibly detailed
    + Single-Cell RNA characterises exact cell types and cell trajectories
    + Spatial transcriptomics used to identify co-located cells in tissue
    + Identify cell-cell signalling *in situ*

## What Is Transcription

:::: {.columns}

::: {.column width='40%'}

### Definition

> Transcription is the process of making an RNA copy of a gene sequence

:::

::: {.column width='60%'}

::: {style="font-size: 90%; text-align: center;"}

![Figure taken from [^1] Licensed under CC-BY 4.0 by OpenStax](transcriptomics/transcription.jpg)

:::

:::

::::

[^1]: https://openoregon.pressbooks.pub/mhccbiology102/chapter/transcription/

## Steps of Transcription 


1. **RNA polymerase binds to the promoter** along with $\geq1$ transcription factors

::: {.incremental}
2. **RNA polymerase creates a transcription bubble**
    + separates the two DNA strands, breaking hydrogen bonds between complementary DNA nucleotides.
3. **RNA polymerase adds RNA nucleotides**
    + complementary to the antisense DNA strand.
4. **RNA sugar-phosphate backbone forms**
5. **Hydrogen bonds of the RNA–DNA complex break** freeing the newly synthesized RNA strand.

:::

## Steps of Transcription {.slide-only .unlisted}

#### If the cell is a eukaryotic cell

6. **RNA processing**
    + This may include polyadenylation, capping and splicing
    + Occurs during (or immediately after) transcription
7. **RNA Localisation**
    + The RNA may remain in the nucleus or exit to the cytoplasm through the nuclear pore complex

::: {.fragment}
- Eukaryotic mRNA, miRNA & snRNA transcription uses *RNA Polymerase II*
    + RNA Pol I: rRNA
    + RNA Pol III: tRNA, 5S RNA some small RNAs
    
:::

## Eukaryotic mRNA Processing

- Nuclear mRNA have 5' cap added
    + Protects single-stranded mRNA from degradation
    + Regulates nuclear export
    + Promotes translation
    
::: {.fragment}
- mRNAs are polyadenylated at the 3' end
    + Also protects from degradation
    + Aids in transcription termination, export and translation
    
:::
::: {.fragment}
- Introns are spliced out as required    
:::


## Eukaryotic mRNA Processing {.slide-only .unlisted}

![Taken from @Shafee2017-zv](transcriptomics/eukaryotic_mrna_processing.svg)

## Alternate Transcripts and Isoforms


![Image by the National Human Genome Research Institute](transcriptomics/DNA_alternative_splicing.png)

## Transcriptome Resources

- Reference Transcriptomes & Genomes are now commonly available
    + Incorporate experimentally derived & predicted sequences + loci
- Gencode[^2] provide highest quality for mouse & human
    + Release 48 (GRCh38): 78,686 genes + 385,669 transcripts

::: {.fragment}
- Other organisms from Ensembl, RefSeq, UCSC etc
     + Zebrafish, Rat, Chicken, Drosophila, Wheat, Yeast, *E. Coli* etc

:::

::: {.fragment}
- Sometimes we build novel transcriptomes from specific tissues
    + e.g. sea snake venom gland, shiraz fruit
    
:::


[^2]: https://www.gencodegenes.org/

# Early Transcriptomics

## Northern Blotting

- Northern blot [@1977NorthernBlot] extended DNA-based methods (i.e Southern blot)
    + Earliest single-gene method
- Gel Electrophoresis then hybridisation with labelled probe
    + Requires some knowledge of RNA sequence
- Images scanned $\rightarrow$ *Densitometric Analysis* for crude quantitation
- Possible for different isoforms to be detected
    + Sequence dependent

## RT-qPCR

::: {.notes}
The C~T~ values as actually estimated to a decimal value
:::

- “Gold-standard” for measurement of transcription levels
    + Single gene $\implies$ not a high-throughput technique
- Targets a single transcript region with specific primers to produce cDNA <br>$\rightarrow$ Polymerase Chain Reaction (PCR)
- Each PCR cycle approximately doubles the target region
    
::: {.fragment}    
- cDNA produced is identified using fluorophores
    + Fluorescence doubles with each cycle
- Once fluorescence passes a detection threshold, the cycle number is recorded
    + Known as the Cycle Threshold (C~T~) value

:::

## RT-qPCR {.slide-only .unlisted}

![A 10-fold dilution series](transcriptomics/qPCR.png){fig-align="left"}

## RT-qPCR {.slide-only .unlisted}

- Higher C~T~ values $\implies$ lower numbers of target molecule at the beginning
- These can be used to estimate and compare abundance levels (i.e. gene expression)

::: {.fragment}
- Is vulnerable to technical artefacts (e.g. pipetting variability)
- Often includes one or more "housekeeper" genes thought to be stably expressed
:::

::: {.incremental}
- C~T~ values are then *normalised* to the housekeeper genes $\implies \Delta C_T$
    + log~2~ transformed values are used
- Comparison between conditions is the change in $\Delta C_T \implies \Delta\Delta C_T$
- Represents change on the log~2~ scale, i.e. *log fold-change*
:::

## Expressed Sequence Tags

::: {.notes}
- The senior author on the EST paper was J Craig Ventner who played an important role in the Human Genome Project
:::

- The first attempt at capturing the larger transcriptome was ESTs [@1991VenterEST]
- Identified 609 human brain mRNA sequences
    + Selected for polyA-mRNA then reverse transcribed
    + Used random primers $\rightarrow$ Sanger Sequencing
- 10 years before the Human Genome Project
    + Gene discovery was a hot topic

## Sanger Sequencing

![Estevezj, [CC BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0), via Wikimedia Commons](transcriptomics/Sanger-sequencing.svg){fig-align="left"}

## SAGE & CAGE

- First high-throughput quantification method was *Serial Analysis of Gene Expression* (SAGE) [@pmid7570003]

:::: {.columns}

::: {.column width="58%"}

::: {.incremental}
- mRNA $\rightarrow$ cDNA using biotinylated primers
- cDNA bound to beads (using biotin) & cleaved 
- 11mer "tags" were ligated into long sequenced using linker sequences
- Sequenced using Sanger Sequencing
- Deconvolution & counting
:::
:::

::: {.column width="42%"}
::: {style="font-size: 80%; text-align: center;"}
![Thomas Shafee, [CC BY 4.0](https://creativecommons.org/licenses/by/4.0), via Wikimedia Commons](transcriptomics/SAGE.png)
:::
:::

::::

## SAGE & CAGE {.slide-only .unlisted}

- The terminology of counting *tags* is still used by some manuals & software
    + Statistical models still form the basis of modern transcriptomics
- Was described as Digital Gene Expression (DGE)
    + The term DGE is still used but easily confused with Differential Gene Expression
    
::: {.fragment}
- A variant called Cap Analysis of Gene Expression (CAGE) targeted the 5' Cap
- Heavily used by FANTOM project [@Abugessaisa2021-fn] to identify exact Transcription Start Sites (TSS)

:::


## Microarray Technology

::: {.notes}
- My search last week showed 69000 public microarray datasets in the GEO database
- I reviewed a Scientific Reports submission using public array data last month
:::

- Microarrays represent the *birth of modern transcriptomics*
    + Thousands of genes could be measured simultaneously!!!
    + Tens of thousands of public datasets $\implies$ still being mined
- Established concurrently with the Human Genome Project (1990-2003)
    + Databases & complete reference sequences become widely available

::: {.incremental}
- All require fluorescently labelled cDNA copies of RNA
- Hybridised to the array using probes for known sequences
    + $\uparrow$ fluorescence $\implies \uparrow$ RNA abundance
:::

## Microarray Technology {.slide-only .unlisted}

- All microarrays follow the same basic process

![Image courtesy of Squidonius, Public domain, via Wikimedia Commons](transcriptomics/Microarray_exp_horizontal.svg)

## Two Colour Arrays

:::: {.columns}

::: {.column width="57%"}

- Two colour microarrays were printed microscope slides
- Known probe sequences were *printed* to the surface in defined locations
    + 60-75mer oligonucleotide probes
    + Highly customisable by project
    + Two samples per array
    
::: {.fragment}
- One sample labelled with Cy5 (Red)
- Other sample labelled with Cy3 (Green)
- Scanned at 570nm (Cy3) and 670nm (Cy5)

:::

:::

::: {.column width="43%"}

::: {.fragment}

![Section of two-colour array taken from @Shalon01071996](transcriptomics/2colour.jpg){width="100%" fig-align="left"}

:::
:::

::::



## Single Channel Arrays

:::: {.columns}

::: {.column width="55%"}


- Affymetrix Arrays became dominant
    + Factory manufactured
- Standardised layout for each organism
- Single sample per array
    + Only scanned at one frequency
- More genes/array

::: {.fragment}
- 25mer probes targeting 3' end of transcript
    + Captured only intact transcripts
:::


:::

::: {.column width="45%"}
::: {style="font-size: 80%"}
![No author known. Schutz assumed based on copyright claims. [CC BY-SA 3.0](http://creativecommons.org/licenses/by-sa/3.0/), via Wikimedia Commons](transcriptomics/Affymetrix.jpg)
:::
:::

::::

## Single Channel Arrays  {.slide-only .unlisted}

:::: {.columns}

::: {.column width='85%'}

<br>

![The basic methodology underpinning Affymetrix array design. Source unknown](transcriptomics/microarrayLayout.jpg){width="100%"}

:::
::::

## 3' Arrays

- Each 3' exon targeted by 11 unique 25mer probes $\implies$ *a probeset*
- Possible to detect different transcripts only if 3' exons differ

::: {.incremental}
- *Perfect Match* (PM) probes $\implies$ exactly matches target sequence
    + Known to capture off-target signal $\implies$ non-specific binding
- Arrays included paired *mismatch* probes (MM) with a change at the 13th position
    + Sometimes returned more signal than PM probes &#129322;
- Gene-level expression estimate obtained taking a robust average across probeset
    + Model also included BG signal (but not always from MM probes)
    
:::

## Whole Transcript Arrays



- Whole Transcript Arrays released by Affymetrix in mid-2000s
    + Marketed as Exon Arrays and Gene Arrays
- Probes along entire transcript *BUT* $\leq$ 4 probes/exon

::: {.fragment}

![Source: Affymetrix Technical Note](transcriptomics/ArrayProbeLayout.png){fig-align="left" width="70%"}
:::

## Whole Transcript Arrays  {.slide-only .unlisted}

::: {.notes}
- Detecting alternate isoform usage on Exon Arrays was the focus of my PhD
- My method was rubbish, but still better than anything else
:::

- No successful methods for determining alternate isoform usage
    + Most people reverted back to gene-level signal
    + No real gains over 3' Arrays beside more genes/array

::: {.fragment}

- RNA-Seq appeared at a similar time & **obliterated** their market share
    + Alternate isoform usage in RNA-seq is *still* considered a bit exploratory

:::

# Microarray Analysis

## Single Channel Data

- We will have multiple arrays from each condition
    + Biological Replicates (hopefully $\geq4$ per condition)
    + Want to find changed expression in response to our biological hypothesis
    
::: {.incremental}
    
- Will the some arrays have higher/lower overall signal?
    + Pipetting errors, hybridisation variability etc

- Two Initial Problems to solve

1. Adjust for overall differences in signal [$\implies$ Normalisation]{.fragment}
2. Removal of Background Signal (non-specific binding + optical noise) <br> [$\implies$Background Correction]{.fragment}

:::

## Normalisation

:::: {.columns}
::: {.column width="65%"}

![Example of raw PM probe intensities. Taken from @pmid12538238](transcriptomics/quantileNorm.png){fig-align="left"}
:::
::: {.column width="35%"}
- The variation here is technical<br>$\implies$ *not* due to biology
- Higher variance reduces power of statistical testing
- Can we reduce this?

::: {.fragment}
- Quantile normalisation
:::
:::
::::

## Normalisation {.slide-only .unlisted}

- Quantile normalisation is perfect for arrays with probes and probesets
    + Normalise probes, but estimate signal at the probeset level

::: {.incremental}
1. Find the lowest signal probe on each array
2. Calculate the average signal across all arrays
3. Give each of the probes the average signal
4. Move to the next lowest signal probe until finished
:::

::: {.fragment}
- The lowest signal probes will be completely different across arrays
- Effectively randomises noise
- Leads to arrays with identical distributions
:::

## Normalisation {.slide-only .unlisted}

:::: {.columns}
::: {.column}
![Before quantile normalisation](transcriptomics/preNorm.png)
:::
::: {.column}
![After quantile normalisation[^3]](transcriptomics/postNorm.png)
:::
::::

- Now we have identical distributions of signal across all arrays
- Equivalent to having identical amounts of source material (mRNA)

[^3]: Images taken from: Bolstad, Probe Level Quantile Normalization for High Density Oligonucleotide Array Data Unpublished Manuscript, 2001

## Background Correction

- Background Correction performed *simultaneously with estimation of signal*
- Robust Multichip Average (RMA) [@rma2003]
    + Estimates signal for each array ($\mu_i$)
    + Model includes probe affinities ($\alpha_j$)
    + Doesn't include MM probes
    + Fitted using robust statistics to reduce impact of outlier probes
    
$$
PM_{ij} = \mu_i + \alpha_j + \epsilon_{ij}
$$
    
::: {.fragment}

- Extended to GC-RMA [@wu2004model] to include GC content of probes

:::

## Differential Expression Analysis

- A primary challenge is to detect where gene expression levels change in response to biological question
    + Often control samples Vs treated samples
- Microarray data is normally distributed on the log~2~ scale
    + Can fit standard regression models
- For Treat Vs Control $\implies$ $T$-test for each gene

::: {.fragment}

$$
H_0: \text{No difference in average gene expression levels}\\
H_A: \text{Some difference in average gene expression levels}
$$

- NB: Experiments estimate the *true* expression level across a theoretical population
:::

## Differential Expression Analysis {.slide-only .unlisted}

- The Bioconductor package `limma` is the industry standard [@pmid16646809]
    + Still heavily used for modern RNA-Seq data
    + Models tailored to managing variances found in transcriptomic datasets

::: {.fragment}
- After testing $\rightarrow$ $p$-value for each gene
- Multiple testing becomes an issue (revise Steven Delean's lecture)
:::

## Multiple Testing

- Researchers commonly use a $p$-value $<0.05$ to claim evidence of significant change
    + Often described as the rejection threshold $\alpha = 0.05$

> A $p$-value represent the probability of observing data (i.e. evidence of change) as extreme, or more extreme than our data if $H_0$ is true

::: {.fragment}

- i.e. how likely are we to see our evidence of change if nothing's actually happening
- Using $\alpha = 0.05$ we will randomly see evidence as strong as observed (or stronger) about 1 in 20 times, *if there's really nothing happening*

:::

## Multiple Testing {.slide-only .unlisted}

- If testing across 10,000 genes $\implies$ 10,000 $p$-values
- If no change between groups in any gene ($H_0$ is always true) <br>$\implies$ about 500 genes will return $p<0.05$
- These would be considered *false discoveries*, *false positives* or *Type I Errors*
    + False negatives are Type II errors


|              | $H_0$ True | $H_0$ False |
|:------------ | ---------- | ----------- |
| **Accept $H_0$** | &#x2705; | Type II Error |
| **Reject $H_0$** | [Type I Error]{.text-red} | &#x2705; |


## Multiple Testing {.slide-only .unlisted}

- Reducing false positives is vital $\implies$ don't want to waste research \$\$\$
- An intuitive solution would be to use a lower value for $\alpha$
    + Using $\alpha = 0.01$ $\implies$ 1 in 100 random $p$-values under $H_0$<br>$\implies$ only 100 false discoveries in 10,000 genes
    + But this makes it harder for *true positives* to be identified <br>$\implies$ more Type II errors (false negatives)
- No perfect solution for minimising Type I errors without increasing Type II errors

## The Bonferroni Correction

- A commonly used approach is the Bonferroni Correction
- $\alpha$ is divided by the number of tests <br>$\implies$ probability of one false discovery remains at the original $\alpha$
    + Known as Family Wise Error Rate (FWER) control

::: {.incremental}
- For $n=10,000$ genes we would use $\alpha^* = \frac{0.05}{n} = 5\times10^{-6}$
- The equivalent is to multiply all $p$-values by $n$ to give adjusted $p$-values
- $p_{adj} = \min(1, p \times n)$ ensures $p$-values are always $\leq1$
    + Referred to as Bonferroni-adjusted $p$-values
    
:::

## The False Discovery Rate

- An alternative is to allow a set proportion of your results to be *false positives*
- Instead of controlling the FWER, we control the False Discovery Rate (FDR)
    + Using $\alpha = 0.05$ $\implies$ 95% of results will be appropriate rejections of $H_0$
    + Is an estimate of the true FDR
    + Effectively allows a small amount of noise into our data
    + For larger network-style or downstream analysis $\implies$ signal drowns out noise
- Is almost always more powerful that the Bonferroni correction
    + More power $\implies$ more ability to find the *true positives*
    
## The False Discovery Rate {.slide-only .unlisted}

::: {.notes}
- The adjustment algorithm is a bit beyond this course
:::
    
- Most common FDR method is the Benjamini-Hochberg adjustment [@BenjaminiHochbergFDR]

::: {.incremental}
1. $p$-values are given rank $i = 1, 2, \ldots, n$ where we have $n$ tests (i.e. genes)
2. Find maximum value of $i$ where $p_i \leq \alpha \frac{i}{n}$

- FDR-adjusted $p$-values easily obtained using `R`
    + `p.adjust(p, method = "BH")`
    
:::

## Closing Comments

- Microarray signal estimates follow a normal distribution ($\mathcal{N}(\mu, \sigma)$) with log-transformed
- We can apply linear regression models
    + In a simple A vs B experiment $\equiv$ $T$-tests
- Estimates of change from DE analysis often referred to as logFC (log fold-change)
- $p$-values are usually FDR-adjusted
    + Gives best compromise of power vs error-rate control

## Closing Comments {.slide-only .unlisted}

- Foundations built during the microarray era enabled analysis of RNA-Seq data
    + RNA-Seq data is not normally distributed
- Core principles and methods developed during this era still apply
    + Normalisation, DE analysis, multiple testing etc
- Many bioinformaticians from the microarray era are still very active
- A lot of development occurred in Australia (e.g. Prof Gordon Smyth, WEHI)
    + Next generation have been trained & mentored at WEHI, USyd etc


## References
